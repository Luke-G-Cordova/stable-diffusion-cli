{
  "model_path": {
    "flags": ["-mp", "--model_path"],
    "default": "./models/stable-diffusion-v2",
    "type": "str",
    "help": "Path to the base model checkpoint to run stable diffusion on. If evaluates to `.ckpt` or `.safetensor` file will convert to and use a huggingface diffusers model stored in `./models` by the same name as the original."
  },
  "scheduler_type": {
    "flags": ["-st", "--scheduler_type"],
    "default": "pndm",
    "type": "str",
    "help": "Scheduler type also known as Sampler type. Can be one of `['pndm', 'lms', 'ddim', 'euler', 'euler-ancestral', 'dpm']`"
  },
  "embeddings_path": {
    "flags": ["-ep", "--embeddings_path"],
    "default": "models/embeddings",
    "type": "str",
    "help": "Path to directory containing textual inversion embedding files."
  },
  "prompt": {
    "flags": ["-p", "--prompt"],
    "default": "None",
    "type": "str",
    "help": "Text prompt used for inferencing"
  },
  "negative_prompt": {
    "flags": ["-n", "--negative_prompt"],
    "default": "None",
    "type": "str",
    "help": "Negative text prompt used for inferencing"
  },
  "prompt_file": {
    "flags": ["-pp", "--prompt_file"],
    "default": "prompts/p.txt",
    "type": "str",
    "help": "A file storing the prompt. --prompt flag must not be set to use this."
  },
  "negative_prompt_file": {
    "flags": ["-np", "--negative_prompt_file"],
    "default": "prompts/n.txt",
    "type": "str",
    "help": "A file storing the negative prompt. --negative_prompt flag must not be set to use this."
  },
  "seed": {
    "flags": ["-s", "--seed"],
    "default": -1,
    "type": "int",
    "help": "Seed. If seed is -1 a random seed will be generated and used."
  },
  "clip_skip": {
    "flags": ["-c", "--clip_skip"],
    "default": 1,
    "type": "int",
    "help": "clip skip"
  },
  "inference_steps": {
    "flags": ["-i", "--inference_steps"],
    "default": 30,
    "type": "int",
    "help": "Amount of inference steps."
  },
  "guidance_scale": {
    "flags": ["-g", "-cfg", "--guidance_scale"],
    "default": 7,
    "type": "float",
    "help": "Guidance scale, cfg scale."
  },
  "width": {
    "flags": ["--width"],
    "default": 512,
    "type": "int",
    "help": "Width of output image."
  },
  "height": {
    "flags": ["--height"],
    "default": 512,
    "type": "int",
    "help": "Height of output image."
  },
  "task": {
    "flags": ["--task"],
    "default": "txt2img",
    "type": "str",
    "help": "Task to preform. One of txt2img or img2img."
  },
  "lora_path": {
    "flags": ["-lp", "--lora_path"],
    "default": "models/lora",
    "type": "str",
    "help": "Path to directory storing lora."
  },
  "out_dir": {
    "flags": ["-op", "--out_dir"],
    "default": "output",
    "type": "str",
    "help": "Path to store generated images and generation data."
  },
  "out_name": {
    "flags": ["-on", "--out_name"],
    "default": "",
    "type": "str",
    "help": "Name added to output file along with its seed. Will store as <out_dir>/<out_name><seed>.png"
  },
  "group_by_seed": {
    "flags": ["-gbs", "--group_by_seed"],
    "action": "store_true",
    "help": "This flag will store each generated image in a dir named after its seed. It's path will be <out_dir>/<seed>/<out_name><seed>.png"
  },
  "batch_size": {
    "flags": ["-bs", "--batch_size"],
    "default": 1,
    "type": "int",
    "help": "batch size"
  },
  "embed_prompts": {
    "flags": ["-e", "--embed_prompts"],
    "action": "store_true",
    "help": "For longer prompts with 77 or more tokens use this flag to first make them embeddings."
  },
  "help_list_lora": {
    "flags": ["-hl", "--help_list_lora"],
    "action": "store_true",
    "help": "Use this flag to find and list lora. This will only look in the models/lora directory."
  },
  "help_list_models": {
    "flags": ["-hm", "--help_list_models"],
    "action": "store_true",
    "help": "Use this flag to find and list lora. This will only look in the models/lora directory."
  },
  "allow_tf32": {
    "flags": ["-atf32", "--allow_tf32"],
    "action": "store_true",
    "help": "Inference will go faster with slight inaccuracy."
  },
  "no_gen_data": {
    "flags": ["-ng", "--no_gen_data"],
    "action": "store_false",
    "help": "Setting this flag prevents generation data from being stored with images."
  },
  "image_path": {
    "flags": ["-ip", "--image_path"],
    "default": "None",
    "type": "str",
    "help": "If task is img2img, this path indicates the input image."
  },
  "image_strength": {
    "flags": ["-is", "--image_strength"],
    "default": 0.8,
    "type": "float",
    "help": "If task is img2img, this path indicates the input image."
  },
  "vae_path": {
    "flags": ["-vp", "--vae_path"],
    "default": "None",
    "type": "str",
    "help": "Path to custom vae file."
  },
  "pose_path": {
    "flags": ["-sp", "--pose_path"],
    "default": "models/poses",
    "type": "str",
    "help": "Path to custom pose directory. If none is provided, will attempt to use default."
  },
  "no_save_init_image": {
    "flags": ["-nsii", "--no_save_init_image"],
    "action": "store_true",
    "help": "Include this flag to not save the init image for img2img"
  }
}
